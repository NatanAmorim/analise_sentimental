{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: unidecode in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.1.1)\nRequirement already satisfied: pandas in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.0.3)\nRequirement already satisfied: numpy>=1.13.3 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (1.18.3)\nRequirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2019.3)\nRequirement already satisfied: six>=1.5 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\nRequirement already satisfied: nltk in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.5)\nRequirement already satisfied: click in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (7.1.1)\nRequirement already satisfied: joblib in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (0.14.1)\nRequirement already satisfied: regex in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (2020.4.4)\nRequirement already satisfied: tqdm in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (4.45.0)\nRequirement already satisfied: sklearn in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.0)\nRequirement already satisfied: scikit-learn in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sklearn) (0.22.2.post1)\nRequirement already satisfied: scipy>=0.17.0 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\nRequirement already satisfied: numpy>=1.11.0 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (1.18.3)\nRequirement already satisfied: joblib>=0.11 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\nRequirement already satisfied: seaborn in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.10.0)\nRequirement already satisfied: pandas>=0.22.0 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from seaborn) (1.0.3)\nRequirement already satisfied: scipy>=1.0.1 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from seaborn) (1.4.1)\nRequirement already satisfied: numpy>=1.13.3 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from seaborn) (1.18.3)\nRequirement already satisfied: matplotlib>=2.1.2 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from seaborn) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas>=0.22.0->seaborn) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas>=0.22.0->seaborn) (2019.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\nRequirement already satisfied: cycler>=0.10 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\nRequirement already satisfied: six>=1.5 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.22.0->seaborn) (1.14.0)\nRequirement already satisfied: matplotlib in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.2.1)\nRequirement already satisfied: python-dateutil>=2.1 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (2.8.1)\nRequirement already satisfied: numpy>=1.11 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.18.3)\nRequirement already satisfied: cycler>=0.10 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (2.4.7)\nRequirement already satisfied: six>=1.5 in c:\\users\\natan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n\n\u001b[1m\u001b[93mImporta√ß√µes feitas com sucesso!\n"
    }
   ],
   "source": [
    "#import string\n",
    "import re # Regex (express√£o regular)\n",
    "!pip install unidecode\n",
    "from unicodedata import normalize # ut√≠l para tratamento de texto e compatibilidade\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "!pip install nltk\n",
    "import nltk # Ferramentas de PLN\n",
    "!pip install sklearn\n",
    "import sklearn # Ferramentas de aprendizado de m√°quina\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "!pip install seaborn\n",
    "import seaborn as sns\n",
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt # Plotagem de gr√°ficosX_train_count\n",
    "\n",
    "print(\"\\n\" + '\\033[1m' + '\\033[93m' + \"Importa√ß√µes feitas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados\n",
    "* As seguintes CSV foram baixados em [Portuguese Tweets for Sentiment Analysis](https://www.kaggle.com/augustop/portuguese-tweets-for-sentiment-analysis) criado por [augustop](https://www.kaggle.com/augustop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                              tweet_text  sentiment\n0                @queren_renata Bom dia, √≥tima semana :)          1\n1                       o frio vai voltar finalmente :))          1\n2                     @kizqe damn fiquei a sorrir mto :)          1\n3      @lopes85 @_Goalpoint \"gentes\" do benfiquist√£o ...          1\n4      @crlhemely Exatamente! E a outra metade √© modi...          1\n...                                                  ...        ...\n39995              Vao cancelar minhas aulas de manh√£ :(          0\n39996  Triste a rejei√ß√£o do Haddad estar pr√≥xima a do...          0\n39997                  @vicevelyn_ Infelizmente tbm n :(          0\n39998                     @r9carloss No entendiii ptm :(          0\n39999                   S√≥ queria estar na minha cama :(          0\n\n[40000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@queren_renata Bom dia, √≥tima semana :)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>o frio vai voltar finalmente :))</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@kizqe damn fiquei a sorrir mto :)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@lopes85 @_Goalpoint \"gentes\" do benfiquist√£o ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@crlhemely Exatamente! E a outra metade √© modi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39995</th>\n      <td>Vao cancelar minhas aulas de manh√£ :(</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39996</th>\n      <td>Triste a rejei√ß√£o do Haddad estar pr√≥xima a do...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39997</th>\n      <td>@vicevelyn_ Infelizmente tbm n :(</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39998</th>\n      <td>@r9carloss No entendiii ptm :(</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39999</th>\n      <td>S√≥ queria estar na minha cama :(</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>40000 rows √ó 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# https://www.kaggle.com/augustop/portuguese-tweets-for-sentiment-analysis\n",
    "\n",
    "arquivo = \"../dados/\" + 'dados_para_treinamento.csv'\n",
    "\n",
    "df_tweets = pd.read_csv(arquivo, sep=\";\", usecols=['tweet_text','sentiment'], index_col=None, header=0, dtype={\"sentiment\":\"int16\"})\n",
    "\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1    20000\n0    20000\nName: sentiment, dtype: int64"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# √© importante que os dados estejam proximos para n√£o criar um 'Bias' muito grande a um tipo\n",
    "df_tweets['sentiment'].value_counts()\n",
    "# 1 = Positivo üôÇ\n",
    "# 0 = Negativo üôÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0        1\n1        1\n2        1\n3        1\n4        1\n        ..\n39995    0\n39996    0\n39997    0\n39998    0\n39999    0\nName: sentiment, Length: 40000, dtype: int16"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_tweets.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0                  @queren_renata bom dia, √≥tima semana :)\n1                         o frio vai voltar finalmente :))\n2                       @kizqe damn fiquei a sorrir mto :)\n3        @lopes85 @_goalpoint \"gentes\" do benfiquist√£o ...\n4        @crlhemely exatamente! e a outra metade √© modi...\n                               ...                        \n39995                vao cancelar minhas aulas de manh√£ :(\n39996    triste a rejei√ß√£o do haddad estar pr√≥xima a do...\n39997                    @vicevelyn_ infelizmente tbm n :(\n39998                       @r9carloss no entendiii ptm :(\n39999                     s√≥ queria estar na minha cama :(\nName: tweet_text, Length: 40000, dtype: object"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Deixando tudo em min√∫sculo\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].str.lower()\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0                  @queren_renata bom dia, √≥tima semana :)\n1                         o frio vai voltar finalmente :))\n2                       @kizqe damn fiquei a sorrir mto :)\n3        @lopes85 @_goalpoint \"gentes\" do benfiquist√£o ...\n4        @crlhemely exatamente! e a outra metade √© modi...\n                               ...                        \n39995                vao cancelar minhas aulas de manh√£ :(\n39996    triste a rejei√ß√£o do haddad estar pr√≥xima a do...\n39997                    @vicevelyn_ infelizmente tbm n :(\n39998                       @r9carloss no entendiii ptm :(\n39999                     s√≥ queria estar na minha cama :(\nName: tweet_text, Length: 40000, dtype: object"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Removendo tudo entre []\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace='\\[.*?\\]', value='', regex=True)\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover links\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace='https?://[A-Za-z0-9./]+', value='', regex=True)\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace='http?://[A-Za-z0-9./]+', value='', regex=True)\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace='wwww?://[A-Za-z0-9./]+', value='', regex=True)\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace='ftp?://[A-Za-z0-9./]+', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0                  @queren_renata bom dia, √≥tima semana :)\n1                         o frio vai voltar finalmente :))\n2                       @kizqe damn fiquei a sorrir mto :)\n3        @lopes @_goalpoint \"gentes\" do benfiquist√£o n√£...\n4        @crlhemely exatamente! e a outra metade √© modi...\n                               ...                        \n39995                vao cancelar minhas aulas de manh√£ :(\n39996    triste a rejei√ß√£o do haddad estar pr√≥xima a do...\n39997                    @vicevelyn_ infelizmente tbm n :(\n39998                        @rcarloss no entendiii ptm :(\n39999                     s√≥ queria estar na minha cama :(\nName: tweet_text, Length: 40000, dtype: object"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Removendo n√∫meros\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace='\\d+', value='', regex=True)\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0                  @queren_renata bom dia, √≥tima semana :)\n1                         o frio vai voltar finalmente :))\n2                       @kizqe damn fiquei a sorrir mto :)\n3        @lopes @_goalpoint \"gentes\" do benfiquist√£o n√£...\n4        @crlhemely exatamente! e a outra metade √© modi...\n                               ...                        \n39995                vao cancelar minhas aulas de manh√£ :(\n39996    triste a rejei√ß√£o do haddad estar pr√≥xima a do...\n39997                    @vicevelyn_ infelizmente tbm n :(\n39998                        @rcarloss no entendiii ptm :(\n39999                     s√≥ queria estar na minha cama :(\nName: tweet_text, Length: 40000, dtype: object"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Removendo #rashtags\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace=r'(\\#\\w+)', value='', regex=True)\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0                                 bom dia, √≥tima semana :)\n1                         o frio vai voltar finalmente :))\n2                              damn fiquei a sorrir mto :)\n3          \"gentes\" do benfiquist√£o n√£o gostam de futeb...\n4               exatamente! e a outra metade √© modinha :))\n                               ...                        \n39995                vao cancelar minhas aulas de manh√£ :(\n39996    triste a rejei√ß√£o do haddad estar pr√≥xima a do...\n39997                                infelizmente tbm n :(\n39998                                  no entendiii ptm :(\n39999                     s√≥ queria estar na minha cama :(\nName: tweet_text, Length: 40000, dtype: object"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Removendo @Mentions\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace=r'(\\@\\w+)', value='', regex=True)\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0                                    bom dia √≥tima semana \n1                            o frio vai voltar finalmente \n2                                damn fiquei a sorrir mto \n3          gentes do benfiquist√£o n√£o gostam de futebol...\n4                   exatamente e a outra metade √© modinha \n                               ...                        \n39995                  vao cancelar minhas aulas de manh√£ \n39996    triste a rejei√ß√£o do haddad estar pr√≥xima a do...\n39997                                  infelizmente tbm n \n39998                                    no entendiii ptm \n39999                       s√≥ queria estar na minha cama \nName: tweet_text, Length: 40000, dtype: object"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Removendo a pontua√ß√£o (EX: \"!?.,/|#$%¬®&\")\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace=r'[^\\w\\s]', value='', regex=True)\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0                                    bom dia otima semana \n1                            o frio vai voltar finalmente \n2                                damn fiquei a sorrir mto \n3          gentes do benfiquistao nao gostam de futebol...\n4                   exatamente e a outra metade e modinha \n                               ...                        \n39995                  vao cancelar minhas aulas de manha \n39996    triste a rejeicao do haddad estar proxima a do...\n39997                                  infelizmente tbm n \n39998                                    no entendiii ptm \n39999                       so queria estar na minha cama \nName: tweet_text, Length: 40000, dtype: object"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Removendo acentua√ß√£o\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].str.normalize('NFKD').str.encode('ASCII', errors='ignore').str.decode('UTF-8')\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\natan\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package rslp to\n[nltk_data]     C:\\Users\\natan\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package rslp is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Uma stopword pode ser considerada uma palavra irrelevante para a an√°lise\n",
    "nltk.download('stopwords')\n",
    "# RSLP(Removedor de Sufixos da L√≠ngua Portuguesa)\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista de stopWords\n",
    "stopWords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "\n",
    "vetorizador = CountVectorizer(stop_words=stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vetorizador.fit_transform(df_tweets.tweet_text)\n",
    "y = df_tweets.sentiment\n",
    "\n",
    "# Separa em amostras de treino -> X_train, y_train e amostras de teste -> X_test y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "modelo = naive_bayes.MultinomialNB()\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = [\n",
    "    'um bom dia',\n",
    "    'que coisa horrivel'\n",
    "]\n",
    "\n",
    "frases_count = vetorizador.transform(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = modelo.predict(frases_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7496"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "modelo.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Frase N¬∞ 1 teve score Positivo üôÇ\nFrase N¬∞ 2 teve score Negativo üôÅ\n"
    }
   ],
   "source": [
    "i = 1\n",
    "for score in teste:\n",
    "    if (score == 1):\n",
    "        sentimento = \"Positivo\" + \" \" + \"\\U0001f642\"\n",
    "    elif (score == 0):\n",
    "        sentimento = \"Negativo\" + \" \" + \"\\U0001f641\"\n",
    "    else:\n",
    "        sentimento = \"None\" + \" \" + \"\\U0001f610\"\n",
    "\n",
    "    print(f\"Frase N¬∞ {i} teve score {sentimento}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit2a25272bf2b345eeaade93773a9e856a",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}