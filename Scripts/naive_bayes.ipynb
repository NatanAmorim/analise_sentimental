{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # Regex (expressão regular)\n",
    "!pip install unidecode\n",
    "from unicodedata import normalize # utíl para tratamento de texto e compatibilidade\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "!pip install nltk\n",
    "import nltk # Ferramentas de PLN\n",
    "!pip install sklearn\n",
    "import sklearn # Ferramentas de aprendizado de máquina\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "!pip install seaborn\n",
    "import seaborn as sns\n",
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt # Plotagem de gráficosX_train_count\n",
    "\n",
    "print(\"\\n\" + '\\033[1m' + '\\033[93m' + \"Importações feitas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados\n",
    "* As seguintes CSV foram baixados em [Portuguese Tweets for Sentiment Analysis](https://www.kaggle.com/augustop/portuguese-tweets-for-sentiment-analysis) criado por [augustop](https://www.kaggle.com/augustop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/augustop/portuguese-tweets-for-sentiment-analysis\n",
    "\n",
    "arquivo = \"../dados/\" + 'train50.csv'\n",
    "\n",
    "df_tweets = pd.read_csv(arquivo, sep=\";\", usecols=['tweet_text','sentiment'], index_col=None, header=0, dtype={\"sentiment\":\"int16\"})\n",
    "\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é importante que os dados estejam proximos para não criar um 'Bias' muito grande a um tipo\n",
    "df_tweets['sentiment'].value_counts()\n",
    "# 1 = Positivo 🙂\n",
    "# 0 = Negativo 🙁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deixando tudo em minúsculo\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].str.lower()\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo tudo entre []\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace='\\[.*?\\]', value='', regex=True)\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover links\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace='https?://[A-Za-z0-9./]+', value='', regex=True)\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace='http?://[A-Za-z0-9./]+', value='', regex=True)\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace='ftp?://[A-Za-z0-9./]+', value='', regex=True)\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace='ftps?://[A-Za-z0-9./]+', value='', regex=True)\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace='wwww?://[A-Za-z0-9./]+', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo números\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace='\\d+', value='', regex=True)\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo #rashtags\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace=r'(\\#\\w+)', value='', regex=True)\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo @Mentions\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace=r'(\\@\\w+)', value='', regex=True)\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo a pontuação (EX: \"!?.,/|#$%¨&\")\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].replace(to_replace=r'[^\\w\\s]', value='', regex=True)\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo acentuação\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].str.normalize('NFKD').str.encode('ASCII', errors='ignore').str.decode('UTF-8')\n",
    "\n",
    "df_tweets['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uma stopword pode ser considerada uma palavra irrelevante para a análise\n",
    "nltk.download('stopwords')\n",
    "# RSLP(Removedor de Sufixos da Língua Portuguesa)\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista de stopWords\n",
    "stopWords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "\n",
    "vetorizador = CountVectorizer(stop_words=stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vetorizador.fit_transform(df_tweets.tweet_text)\n",
    "y = df_tweets.sentiment\n",
    "\n",
    "# Separa em amostras de treino -> X_train, y_train e amostras de teste -> X_test y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = naive_bayes.MultinomialNB()\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = [\n",
    "    'um bom dia',\n",
    "    'que coisa horrivel'\n",
    "]\n",
    "\n",
    "frases_count = vetorizador.transform(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = modelo.predict(frases_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for score in teste:\n",
    "    if (score == 1):\n",
    "        sentimento = \"Positivo\" + \" \" + \"\\U0001f642\"\n",
    "    elif (score == 0):\n",
    "        sentimento = \"Negativo\" + \" \" + \"\\U0001f641\"\n",
    "    else:\n",
    "        sentimento = \"None\" + \" \" + \"\\U0001f610\"\n",
    "\n",
    "    print(f\"Frase N° {i} teve score {sentimento}\")\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit2a25272bf2b345eeaade93773a9e856a",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}